%Section: Work Experience at the top
\sectionTitle{Experience}{\faSuitcase}
%\renewcommand{\labelitemi}{$\bullet$}
\begin{experiences}
  \experience
  {Present}   {Data Engineer}{NL}{Ahold Delhaize}
  {March 2022} {
    \begin{itemize}
      \item Architected and maintained Terraform modules for scalable infrastructure.
      \item Developed and streamlined CI/CD pipelines for efficient deployment processes.
      \item Designed and developed Python software solutions with Kusto integration for automation and auditing.
      \item Provided crucial cross-team deployment support, fostering collaboration and ensuring successful project rollouts.
      \item Demonstrated leadership in Python project initiatives, ensuring design integrity and quality.
      \item Creating ETL data pipelines on Databricks
      \item Designing, developing, and releasing internal data-based tools for auditing and monitoring using Python and other languages
      \item Responsible for Python code reviews within the team
      \item Maintaining and developing Terraform modules
      \item Maintaining and developing Continuous Integration/Deployment pipelines on GitHub Actions
      \item Deploying and maintaining resources on Azure and Kubernetes with ArgoCD
    \end{itemize}
  }
  {Python, Terraform, CI/CD, Azure Kusto, Kubernetes, Azure, DevOps, Git, SQL, Kafka, Prometheus, Grafana, ArgoCD, Docker, Microservices}
  \emptySeparator
  \experience
  {March 2023}   {Data Engineer}{NL}{Xccelerated, part of Xebia}
  {March 2022} {
    \begin{itemize}
      \item Developed and maintained data pipelines and ML models in a cloud environment (Google Cloud) using Python and PySpark
      \item Software development in different technologies such as PySpark, Kafka, Kubernetes and Redis
      \item Design and deploy microservices in a cloud environment
      \item Design and deploy Continuous Integration/Deployment pipelines using Git, Terraform and ArgoCD
    \end{itemize}
  }
  {Python, Google Cloud, Redis, Kafka, Microservices, Git, Terraform, Kubernetes, ArgoCD, DBT, SQL, PySpark, Deep Learning}
  \emptySeparator
  \experience
  {March 2022}   {Data Engineer}{NL}{Dashmote}
  {September 2021} {
    \begin{itemize}
      \item Infrastructure as Code (IaC) with Terraform on AWS, including design and implementation of scripts for service deployments.
      \item Maintenance and optimization of legacy Apache Airflow components in Python.
      \item Deployment and optimization of Docker images using buildkit, caching and multi-stage builds.
      \item Team collaboration and mentorship, design and deployment of production-ready datalake on AWS,
      \item redesign and implementation of DevOps strategies resulting in faster workflows.

    \end{itemize}
  }
  {Python, AWS, Docker, DevOps, Airflow, Git, Terraform, Jenkins, SQL, ETL, CI/CD, Athena}
  \emptySeparator
  \experience
  {June 2020}   {Software Developer}{SP}{EY}
  {June 2019} {
    \begin{itemize}
      \item Contributed to software development for automation and ETL tasks using SQL, Python, Java, and Talend.
      \item Managed Linux systems, including Ubuntu and CentOS, ensuring stability and security.
      \item Developed and prototyped machine learning models for predictive analytics and data engineering.
      \item Full-stack web development.
    \end{itemize}
  }
  {Python, Java, Linux, Machine Learning, SQL, Bash, Windows Server, Talend, ETL, Sage X3, Business Intelligence}
  \emptySeparator
\end{experiences}
